{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import os\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subject02_happy.png', 'subject02_surprised.png', 'subject03_happy.png', 'subject03_surprised.png', 'subject04_happy.png', 'subject04_surprised.png', 'subject05_happy.png', 'subject05_surprised.png', 'subject06_happy.png', 'subject06_surprised.png', 'subject07_happy.png', 'subject07_surprised.png', 'subject08_happy.png', 'subject08_surprised.png', 'subject09_happy.png', 'subject09_surprised.png', 'subject10_happy.png', 'subject10_surprised.png', 'subject11_happy.png', 'subject11_surprised.png', 'subject12_happy.png', 'subject12_surprised.png', 'subject13_happy.png', 'subject13_surprised.png', 'subject14_happy.png', 'subject14_surprised.png', 'subject15_happy.png', 'subject15_surprised.png']\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# Reading the files in the filepath and displaying the filenames in the path.\n",
    "filepath=r\"..\\images\"\n",
    "files=os.listdir(filepath)\n",
    "print(files)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model uses haarcascade xml files to process the image(faces) data.\n",
    "def detect_face(img):\n",
    "    fd=cv2.CascadeClassifier(r\"..\\haarcascade_frontalface_alt.xml\")\n",
    "    faces=fd.detectMultiScale(img,1.3,5)\n",
    "    #print(\"..............\")\n",
    "    #print(faces)\n",
    "    if len(faces)==0:\n",
    "        return None\n",
    "    (x,y,w,h)=faces[0]\n",
    "    return img[y:y+h,x:x+w], (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    xdata=[]\n",
    "    ydata=[]\n",
    "    files=os.listdir(filepath)\n",
    "    for file in files:\n",
    "        if 'happy' or 'surprised' in file:\n",
    "            ipath=filepath+'\\\\'+file\n",
    "            img=io.imread(ipath)\n",
    "            face,area=detect_face(img)\n",
    "            #print(\"**************************\")\n",
    "            #print(face)\n",
    "            #print('---------------------------')\n",
    "            #print(area)\n",
    "            if face is not None:\n",
    "                face=face.astype(numpy.float32)\n",
    "                face=face/(face.max())\n",
    "                face=cv2.resize(face,(120,120))\n",
    "                face=numpy.ndarray.flatten(face)\n",
    "                xdata.append(face)\n",
    "                if 'happy' in file:\n",
    "                    ydata.append('happy')\n",
    "                elif 'surprised' in file:\n",
    "                    ydata.append('surprised')\n",
    "    return xdata,ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The xdata i.e. the train data and the ydata i.e. the test data are returned.\n",
    "xdata,ydata=load_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(xdata))\n",
    "print(len(ydata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The classifier is trained using scikit-learn\n",
    "from sklearn import neighbors\n",
    "alg=neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "xdata=numpy.array(xdata)\n",
    "ydata=numpy.array(ydata)\n",
    "alg.fit(xdata,ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8928571428571429"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The algorithm accuracy is calculated here.\n",
    "alg.score(xdata,ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emotion.pkl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model is pickled.\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(alg,'emotion.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading 'emotion.pkl' pickle file.\n",
    "model=joblib.load('emotion.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function.\n",
    "def predict_face(img):\n",
    "    fd=cv2.CascadeClassifier(r\"..\\haarcascade_frontalface_alt.xml\")\n",
    "    shape=img.shape\n",
    "    if len(shape)==3:\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    faces=fd.detectMultiScale(img,1.3,5)\n",
    "    if len(faces)==0:\n",
    "        return None\n",
    "    (x,y,w,h)=faces[0]\n",
    "    return img[y:y+h,x:x+w], (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img):\n",
    "    face,area=predict_face(img)\n",
    "    face=face.astype(numpy.float32)\n",
    "    print(face)\n",
    "    face=face/(face.max())\n",
    "    face=cv2.resize(face,(120,120))\n",
    "    print(face.shape)\n",
    "    face=numpy.ndarray.flatten(face)\n",
    "    face = face.reshape(1,-1)\n",
    "    out=model.predict(face)\n",
    "    (x,y,w,h)=area\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),[255,0,0],2)\n",
    "    cv2.putText(img,out[0],(x,y),cv2.FONT_HERSHEY_PLAIN,3.5,[0,0,255],2)\n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[216. 216. 215. ... 207. 207. 207.]\n",
      " [215. 215. 216. ... 207. 207. 207.]\n",
      " [215. 215. 216. ... 207. 207. 207.]\n",
      " ...\n",
      " [ 99.  99.  99. ...  96. 112. 141.]\n",
      " [100. 100. 100. ...  89.  99. 118.]\n",
      " [101. 101. 101. ...  89.  89. 100.]]\n",
      "(120, 120)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'surprised'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The emotion prediction done on a single image.\n",
    "img=cv2.imread(r\"..\\surprise1.jpg\")\n",
    "img1=img.astype(numpy.float32)\n",
    "#print(img1.shape)\n",
    "prediction(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
